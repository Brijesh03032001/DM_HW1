{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6615f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brijesh Kumar\n",
    "# ASU ID: 1235332269\n",
    "# CSE 572 - Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762cd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Models (same 9 as the assignment)\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c34228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 1) Load & target split\n",
    "# ------------------------\n",
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "y = train_df[\"Survived\"].astype(int)\n",
    "X = train_df.drop(columns=[\"Survived\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1253844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 2) Tiny-but-mighty features\n",
    "# ------------------------\n",
    "def extract_title(name: str) -> str:\n",
    "    if not isinstance(name, str):\n",
    "        return \"Unknown\"\n",
    "    m = re.search(r\",\\s*([^.,]+)\\.\", name)\n",
    "    t = (m.group(1).strip() if m else \"Unknown\")\n",
    "    if t in {\"Mlle\", \"Ms\"}: t = \"Miss\"\n",
    "    if t == \"Mme\": t = \"Mrs\"\n",
    "    if t in {\"Lady\",\"Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"}:\n",
    "        t = \"Rare\"\n",
    "    return t\n",
    "\n",
    "X[\"Title\"] = X[\"Name\"].apply(extract_title)\n",
    "X[\"FamilySize\"] = X[\"SibSp\"] + X[\"Parch\"] + 1\n",
    "X[\"IsAlone\"] = (X[\"FamilySize\"] == 1).astype(int)\n",
    "X[\"CabinPresent\"] = X[\"Cabin\"].notna().astype(int)\n",
    "X[\"FarePerPerson\"] = X[\"Fare\"] / X[\"FamilySize\"]\n",
    "X[\"Pclass\"] = X[\"Pclass\"].astype(\"category\")  # treat as categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ef4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# 3) Simple, effective group imputations\n",
    "#    (kept minimal; big win vs global medians)\n",
    "# ---------------------------------------\n",
    "# Embarked -> most frequent (global)\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(X[\"Embarked\"].mode().iloc[0])\n",
    "\n",
    "# Fare -> median within (Pclass, Embarked)\n",
    "X[\"Fare\"] = X[\"Fare\"].fillna(\n",
    "    X.groupby([\"Pclass\",\"Embarked\"])[\"Fare\"].transform(\"median\")\n",
    ")\n",
    "\n",
    "# Age -> median within (Title, Pclass)\n",
    "X[\"Age\"] = X[\"Age\"].fillna(\n",
    "    X.groupby([\"Title\",\"Pclass\"])[\"Age\"].transform(\"median\")\n",
    ")\n",
    "\n",
    "# Safety: any stragglers\n",
    "for col, val in [(\"Fare\", X[\"Fare\"].median()), (\"Age\", X[\"Age\"].median())]:\n",
    "    X[col] = X[col].fillna(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79bf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 4) Columns & transformer\n",
    "# ------------------------\n",
    "num_cols = [\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"FamilySize\",\"IsAlone\",\"FarePerPerson\"]\n",
    "cat_cols = [\"Sex\",\"Embarked\",\"Pclass\",\"Title\",\"CabinPresent\"]\n",
    "\n",
    "num_pipe = SimpleImputer(strategy=\"median\")  # already imputed; this is safety\n",
    "cat_pipe = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),\n",
    "                         OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "\n",
    "prep_no_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# For margin/distance models, we add StandardScaler to numerics only\n",
    "prep_with_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler()), num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8a1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 5) Models (tiny nudges, not \"tuning\")\n",
    "#    - scaled where it matters\n",
    "#    - everything else stays simple\n",
    "# ------------------------\n",
    "models = {\n",
    "    \"Support Vector Machines\": make_pipeline(prep_with_scale, SVC(kernel=\"rbf\", C=2.0, gamma=\"scale\", random_state=42)),\n",
    "    \"KNN\": make_pipeline(prep_with_scale, KNeighborsClassifier(n_neighbors=7, weights=\"distance\")),\n",
    "    \"Logistic Regression\": make_pipeline(prep_with_scale, LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    \"Random Forest\": make_pipeline(prep_no_scale, RandomForestClassifier(n_estimators=400, random_state=42)),\n",
    "    \"Naive Bayes\": make_pipeline(prep_no_scale, GaussianNB()),\n",
    "    \"Perceptron\": make_pipeline(prep_with_scale, Perceptron(alpha=1e-4, max_iter=2000, random_state=42)),\n",
    "    \"Stochastic Gradient Descent\": make_pipeline(prep_with_scale, SGDClassifier(loss=\"log_loss\", alpha=1e-4, max_iter=2000, random_state=42)),\n",
    "    \"Linear SVC\": make_pipeline(prep_with_scale, LinearSVC(C=1.5, max_iter=5000, random_state=42)),\n",
    "    \"Decision Tree\": make_pipeline(prep_no_scale, DecisionTreeClassifier(max_depth=6, random_state=42)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e361c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Improved_Score_%\n",
      "                        KNN             98.77\n",
      "              Random Forest             98.77\n",
      "              Decision Tree             87.77\n",
      "    Support Vector Machines             84.85\n",
      "                 Linear SVC             83.50\n",
      "        Logistic Regression             83.39\n",
      "                Naive Bayes             82.15\n",
      "Stochastic Gradient Descent             80.81\n",
      "                 Perceptron             79.35\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# 6) Train-set scores \n",
    "# ------------------------\n",
    "scores = []\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X, y)\n",
    "    acc = round(pipe.score(X, y) * 100, 2)  \n",
    "    scores.append((name, acc))\n",
    "\n",
    "results = (pd.DataFrame(scores, columns=[\"Model\",\"Improved_Score_%\"])\n",
    "           .sort_values(\"Improved_Score_%\", ascending=False)\n",
    "           .reset_index(drop=True))\n",
    "print(results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
